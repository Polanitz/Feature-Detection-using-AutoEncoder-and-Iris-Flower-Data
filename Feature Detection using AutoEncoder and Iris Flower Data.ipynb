{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sb.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     50\n",
       "versicolor    50\n",
       "setosa        50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['species'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Bias\n",
    "X['B']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  B\n",
       "0           5.1          3.5           1.4          0.2  1\n",
       "1           4.9          3.0           1.4          0.2  1\n",
       "2           4.7          3.2           1.3          0.2  1\n",
       "3           4.6          3.1           1.5          0.2  1\n",
       "4           5.0          3.6           1.4          0.2  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(5,1,5),max_iter=1000000,random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X,X)\n",
    "predictions = mlp.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    4.9\n",
       "sepal_width     3.0\n",
       "petal_length    1.4\n",
       "petal_width     0.2\n",
       "B               1.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.73999638, 3.07618225, 1.44303085, 0.17833639, 1.0004184 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(5, 5)\n",
      "(5, 1)\n",
      "(1, 5)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(len(mlp.coefs_))\n",
    "for i in mlp.coefs_:\n",
    "    print (i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = X.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2, 1. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04833450882104276"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = sigmoid(np.dot(samp,mlp.coefs_[0])+mlp.intercepts_[0])\n",
    "l2 = sigmoid(np.dot(l1,mlp.coefs_[1])+mlp.intercepts_[1])\n",
    "l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04833451])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09380016, 3.54710521, 1.45595706, 0.2490054 , 1.00031323])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = sigmoid(np.dot(l2,mlp.coefs_[2])+mlp.intercepts_[2])\n",
    "l4 = np.dot(l3,mlp.coefs_[3])+mlp.intercepts_[3]\n",
    "l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(mlp,samp):\n",
    "    l1 = sigmoid(np.dot(samp,mlp.coefs_[0])+mlp.intercepts_[0])\n",
    "    l2 = sigmoid(np.dot(l1,mlp.coefs_[1])+mlp.intercepts_[1])\n",
    "    return l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cls']=0\n",
    "for k,v in df.iterrows():\n",
    "    df.loc[k,'cls'] = encode(mlp,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.048335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.077885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.071790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.081436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.046654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species       cls\n",
       "0           5.1          3.5           1.4          0.2  setosa  0.048335\n",
       "1           4.9          3.0           1.4          0.2  setosa  0.077885\n",
       "2           4.7          3.2           1.3          0.2  setosa  0.071790\n",
       "3           4.6          3.1           1.5          0.2  setosa  0.081436\n",
       "4           5.0          3.6           1.4          0.2  setosa  0.046654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>setosa</td>\n",
       "      <td>5.006</td>\n",
       "      <td>3.428</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.056892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>versicolor</td>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.358990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>virginica</td>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "      <td>0.508146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal_length  sepal_width  petal_length  petal_width       cls\n",
       "species                                                                   \n",
       "setosa             5.006        3.428         1.462        0.246  0.056892\n",
       "versicolor         5.936        2.770         4.260        1.326  0.358990\n",
       "virginica          6.588        2.974         5.552        2.026  0.508146"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.338837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.383173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.337256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.282937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.341252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.346670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.350336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.368626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.277104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.344637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.534835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.397121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.585842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.460979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.515593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.744849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.339401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.650159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.508755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.637832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species  \\\n",
       "90            5.5          2.6           4.4          1.2  versicolor   \n",
       "91            6.1          3.0           4.6          1.4  versicolor   \n",
       "92            5.8          2.6           4.0          1.2  versicolor   \n",
       "93            5.0          2.3           3.3          1.0  versicolor   \n",
       "94            5.6          2.7           4.2          1.3  versicolor   \n",
       "95            5.7          3.0           4.2          1.2  versicolor   \n",
       "96            5.7          2.9           4.2          1.3  versicolor   \n",
       "97            6.2          2.9           4.3          1.3  versicolor   \n",
       "98            5.1          2.5           3.0          1.1  versicolor   \n",
       "99            5.7          2.8           4.1          1.3  versicolor   \n",
       "100           6.3          3.3           6.0          2.5   virginica   \n",
       "101           5.8          2.7           5.1          1.9   virginica   \n",
       "102           7.1          3.0           5.9          2.1   virginica   \n",
       "103           6.3          2.9           5.6          1.8   virginica   \n",
       "104           6.5          3.0           5.8          2.2   virginica   \n",
       "105           7.6          3.0           6.6          2.1   virginica   \n",
       "106           4.9          2.5           4.5          1.7   virginica   \n",
       "107           7.3          2.9           6.3          1.8   virginica   \n",
       "108           6.7          2.5           5.8          1.8   virginica   \n",
       "109           7.2          3.6           6.1          2.5   virginica   \n",
       "\n",
       "          cls  \n",
       "90   0.338837  \n",
       "91   0.383173  \n",
       "92   0.337256  \n",
       "93   0.282937  \n",
       "94   0.341252  \n",
       "95   0.346670  \n",
       "96   0.350336  \n",
       "97   0.368626  \n",
       "98   0.277104  \n",
       "99   0.344637  \n",
       "100  0.534835  \n",
       "101  0.397121  \n",
       "102  0.585842  \n",
       "103  0.460979  \n",
       "104  0.515593  \n",
       "105  0.744849  \n",
       "106  0.339401  \n",
       "107  0.650159  \n",
       "108  0.508755  \n",
       "109  0.637832  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# calculate mse of predictions (output of the NN) vs. X for:\n",
    "# (2,1,2)\n",
    "# (5,1,5)\n",
    "# (10,1,10)\n",
    "# (15,1,15)\n",
    "# (20,1,20)\n",
    "# (25,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  B\n",
       "0             5.1          3.5           1.4          0.2  1\n",
       "1             4.9          3.0           1.4          0.2  1\n",
       "2             4.7          3.2           1.3          0.2  1\n",
       "3             4.6          3.1           1.5          0.2  1\n",
       "4             5.0          3.6           1.4          0.2  1\n",
       "..            ...          ...           ...          ... ..\n",
       "145           6.7          3.0           5.2          2.3  1\n",
       "146           6.3          2.5           5.0          1.9  1\n",
       "147           6.5          3.0           5.2          2.0  1\n",
       "148           6.2          3.4           5.4          2.3  1\n",
       "149           5.9          3.0           5.1          1.8  1\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_ = X.iloc[:, :4].values\n",
    "X_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.09380016, 3.54710521, 1.45595706, 0.2490054 ],\n",
       "       [4.73999638, 3.07618225, 1.44303085, 0.17833639],\n",
       "       [4.8038786 , 3.16422415, 1.44059487, 0.18934358]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ = predictions[:, :4]\n",
    "pred_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00619984, -0.04710521, -0.05595706, -0.0490054 ],\n",
       "       [ 0.16000362, -0.07618225, -0.04303085,  0.02166361],\n",
       "       [-0.1038786 ,  0.03577585, -0.14059487,  0.01065642]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = (X_ - pred_)\n",
    "d_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.84380126e-05, 2.21890107e-03, 3.13119274e-03, 2.40152889e-03],\n",
       "       [2.56011571e-02, 5.80373454e-03, 1.85165411e-03, 4.69311804e-04],\n",
       "       [1.07907626e-02, 1.27991158e-03, 1.97669167e-02, 1.13559353e-04]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = d_**2\n",
    "d_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00194752, 0.00843146, 0.00798779, 0.00500634])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ = np.mean(d_, axis=1)\n",
    "m_[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04353270138528518"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_ = np.mean(m_)\n",
    "err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.2066\n"
     ]
    }
   ],
   "source": [
    "mlp1 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(2,1,2),max_iter=1000000,random_state=111)\n",
    "mlp1.fit(X,X)\n",
    "pred1 = mlp1.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse1 = mean_squared_error(pred1, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0348\n"
     ]
    }
   ],
   "source": [
    "mlp2 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(5,1,5),max_iter=1000000,random_state=111)\n",
    "mlp2.fit(X,X)\n",
    "pred2 = mlp2.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse2 = mean_squared_error(pred2, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0510\n"
     ]
    }
   ],
   "source": [
    "mlp3 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(10,1,10),max_iter=1000000,random_state=111)\n",
    "mlp3.fit(X,X)\n",
    "pred3 = mlp3.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse3 = mean_squared_error(pred3, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0345\n"
     ]
    }
   ],
   "source": [
    "mlp4 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(15,1,15),max_iter=1000000,random_state=111)\n",
    "mlp4.fit(X,X)\n",
    "pred4 = mlp4.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse4 = mean_squared_error(pred4, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0511\n"
     ]
    }
   ],
   "source": [
    "mlp5 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(20,1,20),max_iter=1000000,random_state=111)\n",
    "mlp5.fit(X,X)\n",
    "pred5 = mlp5.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse5 = mean_squared_error(pred5, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0508\n"
     ]
    }
   ],
   "source": [
    "mlp6 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(25,1,25),max_iter=1000000,random_state=111)\n",
    "mlp6.fit(X,X)\n",
    "pred6 = mlp6.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse6 = mean_squared_error(pred6, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# feature reduction (4->1)\n",
    "# print confusion matrix and accuracy score using 4 feature (original and using 1 feature (cls)).\n",
    "#      split to 33% test, seed = 47\n",
    "#      use RF() and LogReg()\n",
    "#      try for all the five NN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LogReg() and RF() using 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.loc[:, df.columns != 'species']\n",
    "y = df.loc[:, df.columns == 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.where(y =='setosa', 0, y)\n",
    "y=np.where(y =='versicolor', 1, y)\n",
    "y=np.where(y =='virginica', 2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_4: 0.9800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 20]]\n",
      "Accuracy of Random Forest classifier on test set y_gb_4: 0.9600\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  2 19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_4 = logreg.predict(X_test)\n",
    "acc_log_4 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_4: {:.4f}'.format(acc_log_4))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_4)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_4 = rf.predict(X_test)\n",
    "acc_rf_4 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_gb_4: {:.4f}'.format(acc_rf_4))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_4)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogReg() and RF() using 1 feature (cls) (2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df.drop(['species'],axis=1)\n",
    "X3['B']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3['cls1']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls1'] = encode(mlp1,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls2']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls2'] = encode(mlp2,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls3']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls3'] = encode(mlp3,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls4']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls4'] = encode(mlp4,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls5']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls5'] = encode(mlp5,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls6']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls6'] = encode(mlp6,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>cls</th>\n",
       "      <th>B</th>\n",
       "      <th>cls1</th>\n",
       "      <th>cls2</th>\n",
       "      <th>cls3</th>\n",
       "      <th>cls4</th>\n",
       "      <th>cls5</th>\n",
       "      <th>cls6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.048335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.048335</td>\n",
       "      <td>6.293450e-09</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>9.440770e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>6.325430e-09</td>\n",
       "      <td>0.107492</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>2.073627e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>5.875674e-09</td>\n",
       "      <td>0.106785</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>7.082877e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.081436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.081436</td>\n",
       "      <td>6.344351e-09</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>2.559366e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>6.195255e-09</td>\n",
       "      <td>0.081248</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>6.977517e-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width       cls  B  \\\n",
       "0           5.1          3.5           1.4          0.2  0.048335  1   \n",
       "1           4.9          3.0           1.4          0.2  0.077885  1   \n",
       "2           4.7          3.2           1.3          0.2  0.071790  1   \n",
       "3           4.6          3.1           1.5          0.2  0.081436  1   \n",
       "4           5.0          3.6           1.4          0.2  0.046654  1   \n",
       "\n",
       "       cls1      cls2          cls3      cls4      cls5          cls6  \n",
       "0  0.000021  0.048335  6.293450e-09  0.080788  0.006858  9.440770e-34  \n",
       "1  0.000021  0.077885  6.325430e-09  0.107492  0.017227  2.073627e-33  \n",
       "2  0.000021  0.071790  5.875674e-09  0.106785  0.003707  7.082877e-34  \n",
       "3  0.000021  0.081436  6.344351e-09  0.113787  0.015906  2.559366e-33  \n",
       "4  0.000021  0.046654  6.195255e-09  0.081248  0.003641  6.977517e-34  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_11: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_11: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X4 = X3.loc[:, X3.columns == 'cls1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_11 = logreg.predict(X_test)\n",
    "acc_log_11 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_11: {:.4f}'.format(acc_log_11))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_11)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_11 = rf.predict(X_test)\n",
    "acc_rf_11 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_11: {:.4f}'.format(acc_rf_11))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_11)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LogReg() and RF() using 1 feature (cls) (5,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_12: 0.7400\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 13  8]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_12: 0.9200\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  3 18]]\n"
     ]
    }
   ],
   "source": [
    "X5 = X3.loc[:, X3.columns == 'cls2']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X5, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_12 = logreg.predict(X_test)\n",
    "acc_log_12 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_12: {:.4f}'.format(acc_log_12))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_12)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_12 = rf.predict(X_test)\n",
    "acc_rf_12 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_12: {:.4f}'.format(acc_rf_12))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_12)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LogReg() and RF() using 1 feature (cls) (10,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_13: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_13: 0.8800\n",
      "[[20  0  0]\n",
      " [ 0  7  2]\n",
      " [ 0  4 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X6 = X3.loc[:, X3.columns == 'cls3']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X6, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_13 = logreg.predict(X_test)\n",
    "acc_log_13 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_13: {:.4f}'.format(acc_log_13))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_13)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_13 = rf.predict(X_test)\n",
    "acc_rf_13 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_13: {:.4f}'.format(acc_rf_13))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_13)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LogReg() and RF() using 1 feature (cls) (15,1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_14: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_14: 0.8600\n",
      "[[20  0  0]\n",
      " [ 0  6  3]\n",
      " [ 0  4 17]]\n"
     ]
    }
   ],
   "source": [
    "X7 = X3.loc[:, X3.columns == 'cls4']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X7, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_14 = logreg.predict(X_test)\n",
    "acc_log_14 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_14: {:.4f}'.format(acc_log_14))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_14)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_14 = rf.predict(X_test)\n",
    "acc_rf_14 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_14: {:.4f}'.format(acc_rf_14))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_14)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LogReg() and RF() using 1 feature (cls) (20,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_15: 0.8000\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 10 11]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_15: 0.9000\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  4 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X8 = X3.loc[:, X3.columns == 'cls5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X8, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_15 = logreg.predict(X_test)\n",
    "acc_log_15 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_15: {:.4f}'.format(acc_log_15))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_15)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_15 = rf.predict(X_test)\n",
    "acc_rf_15 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_15: {:.4f}'.format(acc_rf_15))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_15)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LogReg() and RF() using 1 feature (cls) (25,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_16: 0.8400\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  8 13]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_16: 0.9000\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  4 17]]\n"
     ]
    }
   ],
   "source": [
    "X9 = X3.loc[:, X3.columns == 'cls6']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X9, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_16 = logreg.predict(X_test)\n",
    "acc_log_16 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_16: {:.4f}'.format(acc_log_16))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_16)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_16 = rf.predict(X_test)\n",
    "acc_rf_16 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_16: {:.4f}'.format(acc_rf_16))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_16)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['4 features LoReg','4 features RF','cls(2,1,2) LoReg', 'cls(2,1,2) RF',\n",
    "          'cls(5,1,5) LoReg', 'cls(5,1,5) RF', 'cls(10,1,10) LoReg', 'cls(10,1,10) RF',\n",
    "          'cls(15,1,15) LoReg', 'cls(15,1,15) RF','cls(20,1,20) LoReg', 'cls(20,1,20) RF',\n",
    "          'cls(25,1,25) LoReg', 'cls(25,1,25) RF']\n",
    "tests_accuracy = [acc_log_4, acc_rf_4, acc_log_11, acc_rf_11, \n",
    "                  acc_log_12, acc_rf_12, acc_log_13, acc_rf_13,\n",
    "                  acc_log_14, acc_rf_14, acc_log_15, acc_rf_15, \n",
    "                  acc_log_13, acc_rf_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>Tests Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4 features LoReg</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4 features RF</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>cls(5,1,5) RF</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>cls(20,1,20) RF</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>cls(25,1,25) RF</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>cls(10,1,10) RF</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>cls(15,1,15) RF</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>cls(20,1,20) LoReg</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>cls(5,1,5) LoReg</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cls(2,1,2) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cls(2,1,2) RF</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>cls(10,1,10) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>cls(15,1,15) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>cls(25,1,25) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Algorithms  Tests Accuracy\n",
       "0     4 features LoReg            0.98\n",
       "1        4 features RF            0.96\n",
       "5        cls(5,1,5) RF            0.92\n",
       "11     cls(20,1,20) RF            0.90\n",
       "13     cls(25,1,25) RF            0.90\n",
       "7      cls(10,1,10) RF            0.88\n",
       "9      cls(15,1,15) RF            0.86\n",
       "10  cls(20,1,20) LoReg            0.80\n",
       "4     cls(5,1,5) LoReg            0.74\n",
       "2     cls(2,1,2) LoReg            0.58\n",
       "3        cls(2,1,2) RF            0.58\n",
       "6   cls(10,1,10) LoReg            0.58\n",
       "8   cls(15,1,15) LoReg            0.58\n",
       "12  cls(25,1,25) LoReg            0.58"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models = pd.DataFrame({ \"Algorithms\": models, \"Tests Accuracy\": tests_accuracy })\n",
    "compare_models.sort_values(by = \"Tests Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = \"Tests Accuracy\", y = \"Algorithms\", data = compare_models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 4 features Random Forest Classifier wins it all here with a maximum accuracy of 0.98."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
